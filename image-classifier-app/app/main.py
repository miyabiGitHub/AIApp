# 1. streamlitã§ç”»åƒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰UIã‚’ä½œæˆ
# 2. ç”»åƒã‚’å‰å‡¦ç†ï¼ˆutilså†…ã®é–¢æ•°ã‚’ä½¿ç”¨ï¼‰
# 3. å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’torch.loadã§èª­ã¿è¾¼ã¿
# 4. æ¨è«–çµæœï¼ˆã‚¯ãƒ©ã‚¹ï¼‰ã‚’è¡¨ç¤º
# 5. ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã¨ç”»åƒã‚’ä¸€ç·’ã«è¡¨ç¤º


# app/main.py

import streamlit as st  # Streamlitã§UIæ§‹ç¯‰
from PIL import Image  # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»åƒã‚’æ‰±ã†ãŸã‚
import torch
import torch.nn as nn
import torchvision.transforms as transforms
import sys
import os

# ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆç”¨ï¼ˆutilsã®preprocessingé–¢æ•°ã‚’ä½¿ã†ãŸã‚ï¼‰
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from utils.preprocessing import preprocess_image  # å‰å‡¦ç†é–¢æ•°ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

# ==========================
# ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã®å®šç¾©ï¼ˆCIFAR-10ï¼‰
# ==========================
classes = ['plane', 'car', 'bird', 'cat', 'deer',
           'dog', 'frog', 'horse', 'ship', 'truck']

# ==========================
# CNNãƒ¢ãƒ‡ãƒ«å®šç¾©ï¼ˆå­¦ç¿’æ™‚ã¨åŒã˜æ§‹é€ ã«ã™ã‚‹å¿…è¦ã‚ã‚Šï¼‰
# ==========================
class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
        self.fc1 = nn.Linear(64 * 8 * 8, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = self.pool(torch.relu(self.conv1(x)))
        x = self.pool(torch.relu(self.conv2(x)))
        x = x.view(-1, 64 * 8 * 8)
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# ==========================
# Streamlit UIãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
# ==========================
st.set_page_config(page_title="ç”»åƒåˆ†é¡AI", layout="centered")
st.title("ğŸ§  ç”»åƒåˆ†é¡AIã‚¢ãƒ—ãƒª")
st.markdown("ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸç”»åƒã‚’åˆ†é¡ã—ã¾ã™ã€‚å¯¾å¿œã‚¯ãƒ©ã‚¹: `CIFAR-10`")

# ==========================
# ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ï¼ˆå­¦ç¿’æ¸ˆãƒ¢ãƒ‡ãƒ«ï¼‰
# ==========================
model = SimpleCNN()
model.load_state_dict(torch.load("models/cifar10_cnn.pt", map_location=torch.device("cpu")))
model.eval()  # æ¨è«–ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆ

# ==========================
# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰UI
# ==========================
uploaded_file = st.file_uploader("ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠï¼ˆä¾‹ï¼š.jpg, .pngï¼‰", type=["jpg", "png"])

if uploaded_file is not None:
    # ç”»åƒã®è¡¨ç¤º
    image = Image.open(uploaded_file)
    st.image(image, caption="ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ç”»åƒ", use_column_width=True)

    # ãƒœã‚¿ãƒ³ã§äºˆæ¸¬å®Ÿè¡Œ
    if st.button("åˆ†é¡ã™ã‚‹"):
        with st.spinner("ç”»åƒã‚’åˆ†é¡ä¸­..."):
            # å‰å‡¦ç†ï¼ˆutilsã®é–¢æ•°ã‚’ä½¿ç”¨ï¼‰
            input_tensor = preprocess_image(image)

            # æ¨è«–å®Ÿè¡Œ
            with torch.no_grad():
                outputs = model(input_tensor)
                _, predicted = torch.max(outputs, 1)
                predicted_class = classes[predicted.item()]

            # çµæœè¡¨ç¤º
            st.success(f"âœ… äºˆæ¸¬ã‚¯ãƒ©ã‚¹: **{predicted_class}**")
